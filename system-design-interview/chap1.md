# 1장 사용자 수에 따른 규모 확장성

이번 장에서는 한 명의 사용자를 지원하는 시스템에서 시작하여, 최종적으로는 몇백만 사용자를 지원하는 시스템을 설계해볼 것 이다.

## 단일 서버

모든 컴포넌트가 단 한 대의 서버에서 실행되는 간단한 시스템을 설계해보자. 웹, 앱, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행된다.

사용자의 요청 처리 흐름부터 살펴보자

1. 사용자는 도메인 이름을 이용하여 웹 사이트에 접속한다. 이 접속을 위해서는 도메인 이름을 DNS에 질의하여 IP 주소로 변환하는 과정이 필요하다.
2. DNS 조회 결과로 IP 주소가 반환된다.
3. 해당 IP 주소로 HTTP 요청이 전달된다.
4. 요청을 받은 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환한다.

이제 실제 요청이 어디로부터 오는지를 살펴보자. 이 요청들은 두 가지 종류의 단말로부터 오는데, 하나는 웹 앱이고, 다른 하나는 모바일 앱이다.

- 웹 애플리케이션: 비즈니스 로직, 데이터 저장 등을 처리하기 위해서는 서버 구현용 언어(자바, 파이썬 등)를 사용하고, 프레젠테이션용으로는 클라이언트 구현용 언어(HTML, 자바스크립트 등)를 사용한다.
- 모바일 앱: 모바일 앱과 웹 서버 간 통신을 위해서는 HTTP 프로토콜을 이용한다. HTTP 프로토콜을 통해서 반환될 응답 데이터의 포맷으로는 보통 JSON이 그 간결함 덕에 널리 쓰인다.

## 데이터베이스

사용자가 늘면 서버 하나로는 충분하지 않아서 여러 서버를 두어야 한다. 하나는 웹/모바일 트래픽 처리 용도고, 다른 하나는 데이터베이스용이다. 이렇게 서버를 분리하면 각각을 독립적으로 확장해 나갈 수 있게 된다.

### 어떤 데이터베이스를 사용할 것인가?

RDBMS vs NoSQL

- RDBMS
  - MySQL, Oracle, PostgreSQL
  - 자료를 테이블과, 열, 칼럼으로 표현
  - SQL을 사용하면 여러 테이블에 있는 데이터를 관계에 따라 조인하여 합칠 수 있다.
- NoSQL
  - CouchDB, Neo4j, Cassandra, HBase, Amazon Dynamo DB
  - 다시 네 분류로 나눌 수 있다.
    - K-V 저장소, 그래프 저장소, 칼럼 저장소, 문서 저장소
  - 일반적으로 NoSQL은 조인 연산을 지원하지 않는다.
- 대부분의 개발자에게는 RDBMS가 최선이지만, 아래와 같은 경우에는 NoSQL이 바람직한 선택일 수 있다.
  - 아주 낮은 응답 지연 시간이 요구됨
  - 다루는 데이터가 비정형이라 관계형 데이터가 아님
  - 데이터를 직렬화하거나 역직렬화 할 수 있기만 하면 됨
  - 아주 많은 양의 데이터를 저장할 필요가 있음

## 수직적 규모 확장 vs 수평적 규모 확장

- 수직적 규모 확장(Vertical scaling): AKA scale up, 서버에 고사양 자원 (더 좋은 CPU, 더 많은 RAM)을 추가하는 행위
- 수평적 규모 확장(AKA scale out): 더 많은 서버를 추가하여 성능을 개선하는 행위

서버로 유입되는 트래픽의 양이 적을 때에는 수직적 확장이 좋은 선택이며, 이 방법의 가장 큰 장점은 단순함이다. 그러나 불행하게도 이 방법에는 몇 가지 심각한 단점이 있다.

- 수직적 규모 확장에는 한계가 있다. 한 대의 서버에 CPU나 메모리를 무한대로 증설할 방법은 없다.
- 수직적 규모 확장법은 장애에 대한 자동 복구(failover) 방안이나 다중화(redundancy) 방안을 제시하지 않는다. 서버가 발생하면 웹사이트/앱은 완전히 중단된다.

이런 단점 때문에, 대규모 애플리케이션을 지원하는 데는 수평적 규모 확장법이 보다 적절하다.

앞서 본 설계에서 사용자는 웹 서버에 바로 연결된다. 웹 서버가 다운되면 사용자는 웹 사이트에 접속할 수 없다. 또한, 너무 많은 사용자가 접속하여 웹 서버가 한계 상황에 도달하게 되면 응답 속도가 느려지거나 서버 접속이 불가능해질 수도 있다. 이런 문제를 해결하는 데는 부하 분산기 또는 로드밸런서를 도입하는 것이 최우선이다.



### 로드밸런서

로드밸런서는 부하 분산 집합(load balancing set)에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다. 

사용자는 로드밸런서의 공개 IP 주소(public ip address)로 접속한다. 따라서 웹 서버는 클라이언트의 접속을 직접 처리하지 않는다. 더 나은 보안을 위해 서버 간 통신에는 사설 IP 주소 (private IP address)가 이용된다. 사설 IP 주소는 같은 네트워크에 속한 서버 사이의 통신에만 쓰일 수 있는 IP 주소로 인터넷을 통해서는 접속할 수 없다. 로드밸런서는 웹 서버와 통신하기 위해 바로 이 사설 주소를 이용한다.

그림 1-4에 나온대로, 부하 분산 집합에 또 하나의 웹 서버를 추가하고 나면 장애를 자동복구하지 못하는 문제(no failover)는 자동으로 해소되며, 웹 계층의 가용성(availability)은 향상된다. 구체적으로 살펴보면 다음과 같다.

- 서버 1이 다운되면, 모든 트래픽은 서버2로 전송된다. 따라서 사이트 전체가 다운되는 일이 방지된다. 부하를 나누기 위해 새로운 서버를 추가할 수도 있다.,
- 웹사이트로 유입되는 트래픽이 가파르게 증가하면, 두 대의 서버로 트래픽을 감당할 수 없는 시점이 오는데, 로드밸런서가 있으므로 우아하게 대처할 수 있다. 웹 서버 계층에 더 많은 서버를 추가하기만 하면 된다. 그러면 로드 밸런서가 자동적으로 트래픽을 분산하기 시작할 것이다.



### 데이터베이스 다중화

위키피디아 

> 많은 DBMS가 다중화를 지원. 보통 서버 사이에 primary - replica 관계를 설정하고 데이터 원본은 주 서버에 사본은 부 서버에 저장하는 방식

쓰기 연산은 primary에서만 지원. Replica는 primary 로 부터 사본을 전달 받으며, 읽기 연산만을 지원. DB를 변경하는 명령들은 primary로 전달되어야 한다. 대부분의 애플리케이션은 읽기 연산이 쓰기 보다 훨씬 높다. 따라서 통상적으로 replica의 수가 primary 보다 많다. DB를 다중화하면 아래와 같은 이점이 있다.

- 더 나은 성능: 모든 데이터 변경 연산은 primary로 전송되고, 읽기 연산은 replica로 전송되기 때문에, 병렬로 처리될 수 있는 질의(query)의 수가 늘어나므로 성능이 좋아진다.
- 안정성, Reliability: 자연재해 등의 이유로 DB 일부가 파괴되더라도 데이터는 보존될 것이다. 데이터를 지역적으로 떨어진 여러 장소에 다중화시켜 놓을 수 있기 때문이다.
- 가용성, Availability: 데이터를 여러 지역에 복제해 둠으로써, 하나의 데이터베이스 서버에 장애가 발생하더라도 다른 서버에 있는 데이터를 가져와 계속할 수 있게 된다.

디비 서버 가운데 하나가 다운되면 어떻게 될까?

- 부 서버가 한대 뿐인데 다운된 경우: 읽기 연산은 한시적으로 모두 primary로 전달된다. 또한 새로운 replica가 장애 서버를 대체하게 된다. 부 서버가 여러 대인 경우에 읽기 연산은 나머지 부 데이터베이스 서버들로 분산될 것이며, 새로운 부 데이터베이스 서버가 장애 서버를 대체할 것이다.
- 주 데이터베이스 서버가 다운되면: 한 대의 부 데이터베이스만 있는 경우 해당 부 데이터베이스 서버가 새로운 주 서버가 될 것이며, 모든 데이터베이스 연산은 일시적으로 새로운 주 서버에서 수행될 것이다. 그리고 새로운 부 서버가 추가될 것이다. 프로덕션 환경에서는 실제로 이보다 복잡하다. 부 서버에 보관된 데이터가 최신 상태가 아닐 수 있기 때문이다. 없는 데이터는 복구 스크립트를 돌려서 추가해야 한다.

이 설계안은 다음과 같이 동작한다. 

- 사용자는 DNS로부터 로드 밸런서의 공개 IP 주소를 받는다.
- 사용자는 해당 IP 주소를 사용해 로드 밸런서에 접속한다.
- HTTP 요청은 서버 1이나 서버2로 전달된다.
- 웹 서버는 사용자의 데이터를 부 데이터베이스 서버에서 읽는다.
- 웹 서버는 데이터 변경 연산은 주 데이터베이스로 전달한다.



이제 응답시간을 개선해 볼 차례이다. 응답 시간은 캐시를 붙이고 정적 콘텐츠를 CDN으로 옮기면 개선할 수 있다.

### 캐시

캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소다.

#### 캐시 계층

캐시 계층은 데이터가 잠시 보관되는 곳으로 데이터베이스보다 훨씬 빠르다. 별도의 캐시 계층을 두면 성능이 개선될 뿐 아니라 데이터베이스의 부하를 줄일 수 있고, 캐시 계층의 규모를 독립적으로 확장시키는 것도 가능해진다.

요청을 받은 웹 서버는 캐시에 응답이 저장되어 있는지를 본다. 저장되어 있다면 해당 데이터를 클라이언트에게 반환한다. 없는 경우에는 데이터베이스 질의를 통해 데이터를 찾아 캐시에 저장한 후 클라이언트에게 반환한다. 이런 캐시 전략을 읽기 주도형 캐시 전략이라고 부른다. 이 외에도 다양한 캐시 전략이 있다.

캐시 서버를 이용하는 방법은 간단하다. 대부분의 캐시 서버들이 일반적으로 널리 쓰이는 프로그래밍 언어로 API를 제공하기 때문이다.

#### 캐시 사용시 유의 점

- 캐시는 어떤 상황에 바람직한가? 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어난다면 고려해볼만 하다
- 어떤 데이터를 캐시에 두어야 하는가? 캐시는 데이터를 휘발성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다. 예를 들어, 캐시 서버가 재시작되면 캐시 내의 모든 데이터는 사라진다. 중요한 데이터는 여전히 persistent data store에 두어야 한다.
- 캐시에 보관된 데이터는 어떻게 만료 되는가? 이에 대한 정책을 마련해 두는 것은 좋은 습관이다. 만료된 데이터는 캐시에서 삭제되어야 한다. 만료 정책이 없으면 캐시에 계속 남게 된다. 만료 기한은 너무 짧으면 곤란한데, 데이터베이스를 너무 자주 읽게될 것이기 때문이다. 너무 길어도 곤란한데, 원본과 차이가 날 가능성이 높아지기 때문이다.
- 일관성은 어떻게 유지되는가? 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부다. 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 이 일관성은 깨질 수 있다. 여러 지역에 걸쳐 시스템을 확장해 나가는 경우 캐시와 저장소 사이의 일관성을 유지하는 것은 어려운 문제가 된다.
- 장애에는 어떻게 대처할 것인가? 캐시 서버를 한 대만 사용할 경우, 해당 서버는 SPOF가 될 가능성이 있다. 위키피디아에 따르면 SPOF의 정의는 "어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는 경우 해당 지점을 단일 장애 지점이라고 부른다" 결과적으로, SPOF를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다.
- 캐시 메모리는 얼마나 크게 잡을 것인가? 캐시 메모리가 너무 작으면 액세스 패턴에 따라서는 데이터가 너무 자주 캐시에서 밀려나(evicted) 캐시의 성능이 떨어지게 된다. 이를 막을 한 가지 방법은 캐시 메모리를 과할당하는 것이다. 이렇게 하면 캐시에 보관될 데이터가 갑자기 늘어났을 때 생길 문제도 방지할 수 있게 된다.
- 데이터 방출(eviction) 정책은 무엇인가? 캐시가 꽉 차버리면 추가로 캐시에 데이터를 넣어야 할 경우 기존 데이터를 내보내야 한다. 이것을 캐시 데이터 방출 정책이라 한다. 이 중 널리 쓰이는 것은 LRU(Least Recently Used)이다. 다음 정책으로는 LFU(Least Frequently Used)나 FIFO가 있으며 경우에 맞게 적용 가능하다.

### CDN (콘텐츠 전송 네트워크)

CDN은 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크이다. 이미지, 비디오, CSS, JavaScript 파일 등을 캐시할 수 있다.

동적 콘텐츠 캐싱은 상대적으로 새로운 개념으로서, 간단하게만 요약하자면 요청 경로, 질의 문자열, 쿠키, 요청 헤더 등의 정보에 기반하여 HTML 페이지를 캐시하는 것이다. 이 책에서는 정적 콘텐츠를 캐시하는 방법에만 집중할 것이다.

CDN이 어떻게 동작하는지를 개략적으로만 살펴보면 다음과 같다. 어떤 사용자가 웹 사이트를 방문하면, 그 사용자에게 가장 가까운 CDN 서버가 정적 콘텐츠를 전달하게 된다. 사용자가 멀면 멀수록 웹 사이트는 천천히 로드될 것이다. 

CDN은 아래와 같이 동작한다.

1. 사용자 A가 이미지 URL을 통해 image.png에 접근한다. URL의 도메인은 CDN 서비스 사업자가 제공한 것이다.
2. CDN 서버의 캐시에 해당 이미지가 없으면, 서버는 원본 서버에 요청하여 파일을 가져온다. 원본 서버는 웹 서버일 수도 있고, 아마존 S3와 같은 온라인 저장소일 수도 있다.
3. 원본 서버가 파일을 CDN 서버에 반환한다. 응답의 HTTP 헤더는 해당 파일이 얼마나 오래 캐시될 수 있는지를 설명하는 TTL 값이 들어있다.
4. CDN 서버는 파일을 캐시하고 사용자 A에게 반환한다. 이미지는 TTL에 명시된 시간이 끝날 때까지 캐시된다.
5. 사용자 B가 같은 이미지에 대한 요청을 CDN 서버에 전송한다.
6. 만료되지 않은 이미지에 대한 요청은 캐시를 통해 처리된다.

#### CDN 사용시 고려해야 할 사항

- 비용: CDN으로 들어가고 나가는 데이터 전송 양에 따라 요금을 내게 된다. 자주 사용되지 않는 콘텐츠를 캐싱하는 것은 이득이 크지 않으므로 CDN에서 빼는 것을 고려하자.
- 적절한 만료 시한 설정: time-sensitive 컨텐츠의 경우 만료 시점을 잘 정해야 한다. 너무 길지도 짧지도 않아야 하는데, 너무 길면 컨텐츠의 신선도가 떨어지고, 너무 짧으면 원본 서버에 너무 빈번하게 접속해야 한다.
- CDN 장애에 대한 대처 방안: 가령 일시적으로 CDN이 죽었을 경우, 해당 문제를 감지하여 원본 서버로부터 직접 콘텐츠를 가져오도록 클라이언트를 구성하는 것이 필요할 수도 있다.
- 콘텐츠 무효화 방법: 아직 만료되지 않은 콘텐츠라 하더라도 아래 방법 가운데 하나를 쓰면 CDN에서 제거할 수 있다.
  - CDN 서비스 사업자가 제공하는 API를 이용하여 콘텐츠 무효화
  - 콘텐츠의 다른 버전을 서비스하도록 오브젝트 버저닝 이용. 콘텐츠의 새로운 버전을 지정하기 위해서는 URL 마지막에 버전 번호를 인자로 주면된다. 예를 들어, image.png?v=2와 같은 식이다.

### 무상태 "stateless" 웹 계층

웹 계층을 수평적으로 확장하는 방법을 고민해 볼 순서다. 이를 위해서는 상태 정보(사용자 세션 데이터와 같은)를 웹 계층에서 제거해야 한다. 바람직한 전략은 상태 정보를 지속성 저장소에 보관하고, 필요할 때 가져오도록 하는 것이다. 이렇게 구성된 웹 계층을 무상태 웹 계층이라 부른다.

#### 상태 정보 의존적인 아키텍처

상태 정보를 보관하는 서버와 그렇지 않은 서버 사이에는 몇 가지 중요한 차이가 있다. 상태 정보를 보관하는 서버는 클라이언트 정보, 즉 상태를 유지하여 요청들 사이에 공유되도록 한다. 무상태 서버에는 이런 장치가 없다.

상태 정보 의존적인 아키텍처의 경우, 특정 사용자의 HTTP 요청은 반드시 해당 사용자의 정볼르 가지고 있는 서버로 전송되어야 한다. 문제는 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 한다는 것인데, 대부분의 로드밸런서가 이를 지원하기 위해 고정 세션(sticky session) 기능을 제공한다. 하지만, 이는 로드밸런서에 부담을 준다. 또한, 로드밸런서 뒷 단에 서버를 추가하거나 제거하기도 까다로워지고 서버의 장애를 처리하기에도 복잡해진다.

#### 무상태 아키텍처

무상태 아키텍처에서 사용자로부터의 요청은 어떤 웹 서버로도 전달될 수 있다. 웹 서버는 상태 정보가 필요할 경우 공유 저장소로부터 데이터를 가져온다. 따라서 상태 정보는 웹 서버로부터 물리적으로 분리되어 있다.

이 공유 저장소는 RDBMS일 수도, Memcached/Redis와 같은 캐시 시스템 일수도, NoSQL일 수도 있다.

### 데이터 센터

두 개의 데이터센터를 이용할 경우, 사용자는 장애가 없는 상황에서는 가장 가까운 데이터 센터로 안내된다. 이 절차를 geoDNS-routing 또는 geo-routing이라고 부른다. 지리적 라우팅에서의 geoDNS는 사용자의 위치에 따라 도메인 이름을 알면 어떤 IP 주소로 변환할지 결정할 수 있도록 해주는 DNS 서비스다. 

두 개의 데이터 센터를 이용한다고 했을 때, x%의 사용자는 US-East 센터로 그리고 (100-x)%의 사용자는 US-West 센터로 안내된다고 하자. 

이들 데이터 센터 중 하나에 심각한 장애가 발생하면 모든 트래픽은 장애가 없는 데이터 센터로 전송된다. 이 사례와 같은 다중 데이터센터 아키텍처를 만들려면 몇가지 기술적 난제를 해결해야 한다.

- 트래픽 우회: 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야 한다. GeoDNS는 사용자에게서 가장 가까운 데이터 센터로 트래픽을 보낼 수 있도록 해준다.
- 데이터 동기화: 데이터 센ㅌ터마다 별도의 데이터베이스를 사용하고 있는 상황이라면, 장애가 자동으로 복구되어(failover) 트래픽이 다른 데이터베이스로 우회된다고 해도, 해당 데이터센터에는 찾는 데이터가 없을 수 있다. 이런 상황을 막는 보편적 전략은 데이터를 여러 데이터 센터에 걸쳐 다중화하는 것이다.
- 테스트와 배포: 여러 데이터 센터를 사용하도록 시스템이 구성된 상황이라면 웹 사이트 또는 애플리케이션을 여러 위치에서 테스트해보는 것이 중요하다. 한편, 자동화된 배포 도구는 모든 데이터 센터에 동일한 서비스가 설치되도록 하는 데 중요한 역할을 한다.

시스템을 더 큰 규모로 확장하기 위해서는 시스템의 컴포넌트를 분리하여 각기 독립적으로 확장될 수 있도록 하여야 한다. 메시지 큐는 많은 실제 분산 시스템이 이 문제를 풀기 위해 채용하고 있는 핵심적 전략 가운데 하나다.



